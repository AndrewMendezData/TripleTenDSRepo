{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greed Seed Supermarket System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid black; padding: 10px; margin: 10px\">\n",
    "\n",
    "The Green Seed Supermarket company wanted to develop a system that can detect if an underage customer is attempting to purchase alcohol. We used Computer Vision to help build a model that would verify a personâ€™s age using cameras at the checkout counters. We used the Tensorflow library to help create a model that would help Green Seed Supermarket accomplish this goal.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet50, preprocess_input\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "SEED = 12345\n",
    "IMG_SIZE = (160, 160)  \n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR = 'final_files/'\n",
    "CSV_PATH = 'labels.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)  # cols: file_name, real_age\n",
    "assert{'file_name','real_age'}.issubset(df.columns)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing size and distribution of dataset\n",
    "\n",
    "print(f\"Total Images: {len(df):,}\")\n",
    "print(f\"Age Stats:\\n{df['real_age'].describe()}\")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "df['real_age'].hist(bins=40)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age'); plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Impressions of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking samples across all percentiles for overall impression of data\n",
    "\n",
    "# Sorting by age\n",
    "df_sorted = df.sort_values('real_age').reset_index(drop=True)\n",
    "\n",
    "# Pick evenly spaced positions (0%..100%)\n",
    "pos = (np.linspace(0, 1, 12) * (len(df_sorted) - 1)).astype(int)\n",
    "\n",
    "# Selecting those rows\n",
    "sel = df_sorted.iloc[pos]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "for ax, (_, row) in zip(axes.ravel(), sel.iterrows()):\n",
    "    img = tf.keras.utils.load_img(os.path.join(DATA_DIR, row['file_name']))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Age {int(row['real_age'])}\")\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid black; padding: 10px; margin: 10px\">\n",
    "\n",
    "From our age distribution above, we can see that the majority of the data includes pictures of people between the ages of 10 and 50 years old. \n",
    "<br>\n",
    "\n",
    "We can also see, from the distribution of photos above that we have a wide array of qualities that we're working with:\n",
    "    <ul>\n",
    "        <li>Differing brightness and contrast in photos</li>\n",
    "        <li>Some are in black and white, others color</li>\n",
    "        <li>Some photos are less focused than others</li>\n",
    "    </ul>\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reads labels.csv and returns a TRAIN generator.\n",
    "    75/25 split\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Splitting data\n",
    "    train_df, val_df = train_test_split(df, test_size=0.25, random_state=SEED, shuffle=True)\n",
    "\n",
    "    # Augmentations & Backbone Freezing\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.1\n",
    "    )\n",
    "\n",
    "    train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=DATA_DIR,\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='raw',     # regression\n",
    "        shuffle=True,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    # Copying validation set for reuse\n",
    "    load_train._val_df = val_df.copy()\n",
    "    return train_gen_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the VALIDATION/TEST generator (the 25% split from load_train).\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "    if not hasattr(load_train, \"_val_df\"):\n",
    "        df = pd.read_csv(path)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        _, val_df = train_test_split(df, test_size=0.25, random_state=SEED, shuffle=True)\n",
    "    else:\n",
    "        val_df = load_train._val_df\n",
    "\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    val_gen_flow = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        directory=DATA_DIR,\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='raw',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return val_gen_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds a small transfer-learning model for age regression\n",
    "    \"\"\"\n",
    "    \n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    base = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1)  # regression output: predicted age\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(1e-3), loss='mae', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data,\n",
    "                batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "    \"\"\"\n",
    "    Trains the model\n",
    "    \"\"\"\n",
    "    \n",
    "    import math\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = math.ceil(train_data.samples / train_data.batch_size)\n",
    "    if validation_steps is None:\n",
    "        validation_steps = math.ceil(test_data.samples / test_data.batch_size)\n",
    "\n",
    "    es = EarlyStopping(monitor='val_mae', patience=3, restore_best_weights=True)\n",
    "    rlrop = ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    # Train head only (backbone frozen)\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=[es, rlrop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Script to Run on the GPU Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to run on the GPU platform\n",
    "\n",
    "script_text = \"\"\"\n",
    "import os, math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "SEED = 12345\n",
    "IMG_SIZE = (160, 160)          # smaller than 224 (default)\n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR = '/datasets/faces/final_files/'\n",
    "CSV_PATH = '/datasets/faces/labels.csv'\n",
    "\n",
    "def load_train(path):\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df = pd.read_csv(path)\n",
    "    train_df, val_df = train_test_split(df, test_size=0.25, random_state=SEED, shuffle=True)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.1\n",
    "    )\n",
    "    train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df, directory=DATA_DIR,\n",
    "        x_col='file_name', y_col='real_age',\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "        class_mode='raw', shuffle=True, seed=SEED\n",
    "    )\n",
    "    load_train._val_df = val_df.copy()\n",
    "    return train_gen_flow\n",
    "\n",
    "def load_test(path):\n",
    "    import pandas as pd\n",
    "    if not hasattr(load_train, '_val_df'):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        df = pd.read_csv(path)\n",
    "        _, val_df = train_test_split(df, test_size=0.25, random_state=SEED, shuffle=True)\n",
    "    else:\n",
    "        val_df = load_train._val_df\n",
    "\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    val_gen_flow = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df, directory=DATA_DIR,\n",
    "        x_col='file_name', y_col='real_age',\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "        class_mode='raw', shuffle=False\n",
    "    )\n",
    "    return val_gen_flow\n",
    "\n",
    "def create_model(input_shape):\n",
    "    base = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for l in base.layers: l.trainable = False\n",
    "    model = Sequential([base, GlobalAveragePooling2D(), Dropout(0.2), Dense(128, activation='relu'), Dense(1)])\n",
    "    model.compile(optimizer=Adam(1e-3), loss='mae', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_data, test_data, epochs=20):\n",
    "    steps_per_epoch = math.ceil(train_data.samples / train_data.batch_size)\n",
    "    val_steps = math.ceil(test_data.samples / test_data.batch_size)\n",
    "    es = EarlyStopping(monitor='val_mae', patience=3, restore_best_weights=True)\n",
    "    rlrop = ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    model.fit(train_data, validation_data=test_data, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch, validation_steps=val_steps,\n",
    "              callbacks=[es, rlrop], verbose=1)\n",
    "\n",
    "    # short fine-tune\n",
    "    base = model.layers[0]\n",
    "    for l in base.layers[-10:]: l.trainable = True\n",
    "    model.compile(optimizer=Adam(1e-4), loss='mae', metrics=['mae'])\n",
    "    model.fit(train_data, validation_data=test_data, epochs=5,\n",
    "              steps_per_epoch=steps_per_epoch, validation_steps=val_steps,\n",
    "              callbacks=[es, rlrop], verbose=1)\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_gen = load_train(CSV_PATH)\n",
    "    val_gen   = load_test(CSV_PATH)\n",
    "    model     = create_model(IMG_SIZE + (3,))\n",
    "    model     = train_model(model, train_gen, val_gen, epochs=20)\n",
    "    print('VAL â†’', model.evaluate(val_gen, verbose=0))\n",
    "\"\"\"\n",
    "\n",
    "with open('run_model_on_gpu.py', 'w') as f:\n",
    "    f.write(script_text)\n",
    "\n",
    "print(\"Wrote run_model_on_gpu.py. Upload this file to the GPU platform and run it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid black; padding: 10px; margin: 10px\">\n",
    "\n",
    "(Output from GPU platform below)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/20<br>\n",
    "356/356 - 35s - loss: 95.3532 - mae: 7.4339 - val_loss: 124.3362 - val_mae: 8.4921<br>\n",
    "Epoch 2/20<br>\n",
    "356/356 - 35s - loss: 76.8372 - mae: 6.6707 - val_loss: 127.6357 - val_mae: 8.6035<br>\n",
    "Epoch 3/20<br>\n",
    "356/356 - 35s - loss: 69.9428 - mae: 6.3992 - val_loss: 91.1531 - val_mae: 7.4454<br>\n",
    "Epoch 4/20<br>\n",
    "356/356 - 35s - loss: 64.4249 - mae: 6.1407 - val_loss: 124.0287 - val_mae: 8.3481<br>\n",
    "Epoch 5/20<br>\n",
    "356/356 - 35s - loss: 52.8486 - mae: 5.5913 - val_loss: 109.1004 - val_mae: 8.2192<br>\n",
    "Epoch 6/20<br>\n",
    "356/356 - 35s - loss: 46.3094 - mae: 5.2223 - val_loss: 85.1038 - val_mae: 7.0332<br>\n",
    "Epoch 7/20<br>\n",
    "356/356 - 35s - loss: 38.2617 - mae: 4.7951 - val_loss: 92.0900 - val_mae: 7.3359<br>\n",
    "Epoch 8/20<br>\n",
    "356/356 - 35s - loss: 37.4804 - mae: 4.7402 - val_loss: 80.0016 - val_mae: 6.7239<br>\n",
    "Epoch 9/20<br>\n",
    "356/356 - 35s - loss: 33.5237 - mae: 4.4271 - val_loss: 83.2579 - val_mae: 6.8529<br>\n",
    "Epoch 10/20<br>\n",
    "356/356 - 35s - loss: 28.5170 - mae: 4.1411 - val_loss: 83.5056 - val_mae: 6.9629<br>\n",
    "Epoch 11/20<br>\n",
    "356/356 - 35s - loss: 27.0142 - mae: 3.9700 - val_loss: 92.1290 - val_mae: 7.1866<br>\n",
    "Epoch 12/20<br>\n",
    "356/356 - 35s - loss: 27.4564 - mae: 4.0428 - val_loss: 185.6307 - val_mae: 11.4591<br>\n",
    "Epoch 13/20<br>\n",
    "356/356 - 35s - loss: 23.7961 - mae: 3.7407 - val_loss: 92.3429 - val_mae: 7.2467<br>\n",
    "Epoch 14/20<br>\n",
    "356/356 - 35s - loss: 24.6167 - mae: 3.8116 - val_loss: 92.4542 - val_mae: 7.1401<br>\n",
    "Epoch 15/20<br>\n",
    "356/356 - 35s - loss: 22.2604 - mae: 3.6746 - val_loss: 82.5822 - val_mae: 6.7841<br>\n",
    "Epoch 16/20<br>\n",
    "356/356 - 35s - loss: 20.1899 - mae: 3.4430 - val_loss: 86.3830 - val_mae: 6.8304<br>\n",
    "Epoch 17/20<br>\n",
    "356/356 - 35s - loss: 17.3425 - mae: 3.2205 - val_loss: 78.4369 - val_mae: 6.6419<br>\n",
    "Epoch 18/20<br>\n",
    "356/356 - 35s - loss: 16.5249 - mae: 3.1295 - val_loss: 81.7731 - val_mae: 6.7226<br>\n",
    "Epoch 19/20<br>\n",
    "356/356 - 35s - loss: 16.6140 - mae: 3.1421 - val_loss: 80.9727 - val_mae: 6.9908<br>\n",
    "Epoch 20/20<br>\n",
    "356/356 - 35s - loss: 17.0187 - mae: 3.1785 - val_loss: 93.4115 - val_mae: 7.6512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid black; padding: 10px; margin: 10px\">\n",
    "\n",
    "Lowest Validation MAE: **6.64** (goal was less than or equal to 8)\n",
    "<br><br>\n",
    "    \n",
    "We used **MobileNetV2** for better processing, utilized augmentation strategies and and pretrained features which helped deliver strong generalization without overfitting. We were able to achieve the goal metric with MAE scoring and the model is within the parameters for the scope of what the company needs for their task.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
